---
title: "Polices d'assurance"
author: "Idriss Louzi, Martin Youssef, Alex Irani, Théophile Schmutz"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    
    # Overall theme
    theme: flatly
    highlight: tango
    code_folding: show
    
    # Table of contents
    number_sections: true
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(rmarkdown)
library(dplyr)
library(caret)
library(kableExtra)
library(ggplot2)
library(broom)
library(tidyr)
library(GGally)
library(glmnet)
library(rcompanion)
library(reshape2)
library(caret)
library(MASS)
library(Metrics)
library(tibble)

set.seed(2025)
custom <- trainControl(
  method = 'repeatedcv',
  number = 5,  # Using 5-fold cross-validation
  repeats = 3,  # Repeating 3 times for robustness
  summaryFunction = defaultSummary,  # Default metrics (RMSE, MAE)
  allowParallel = TRUE  # Use parallel processing if resources allow
)

rmse_c <- function(actuals, predictions) {
  # Définition des classes
  C_1 <- which(actuals %in% c(0, 1))
  C_2 <- which(actuals == 2)
  C_3 <- which(actuals == 3)
  C_4 <- which(actuals > 3)
  
  # Calcul du RMSE pour chaque classe (en évitant les erreurs si une classe est vide)
  rmse_1 <- rmse(actuals[C_1], predictions[C_1]) 
  rmse_2 <- rmse(actuals[C_2], predictions[C_2]) 
  rmse_3 <- rmse(actuals[C_3], predictions[C_3]) 
  rmse_4 <- rmse(actuals[C_4], predictions[C_4]) 
  
  # Combinaison des RMSE (en ignorant les valeurs NA)
  rmse_values <- c(rmse_1, rmse_2, rmse_3, rmse_4)
  RMSE_C <- mean(rmse_values, na.rm = TRUE)  # Moyenne des RMSE valides
  
  # Affichage des résultats
  cat("RMSE_1 (classe très fréquente) :", rmse_1, "\n")
  cat("RMSE_2 (classe fréquente) :", rmse_2, "\n")
  cat("RMSE_3 (classe rare) :", rmse_3, "\n")
  cat("RMSE_4 (classe très rare) :", rmse_4, "\n")
  cat("RMSE combiné (RMSE_C) :", RMSE_C, "\n")
  
  return(RMSE_C)
}
```

# Données

```{r}
data <-read.csv('train_set.csv', header = T, sep = ",",dec=".")
data <- data %>% dplyr::select(-PolID)
train_index <- createDataPartition(data$Claim, p = 0.7, list = FALSE)
train <- data[train_index,]
paged_table(train)
```

```{r}
data$TrancheAge <- cut(data$Age, 
                        breaks = c(-Inf, 25, 35, 45, 55, 65, 110), 
                        labels = c("Moins de 25 ans", "25-34 ans", "35-44 ans", 
                                   "45-54 ans", "55-64 ans", "65 ans et plus"), 
                        right = FALSE)
data <- data %>%
  mutate(TrancheBonus_Malus = case_when(
    Bonus_Malus < 100 ~ "Bonus",
    Bonus_Malus == 100 ~ "Neutre",         # 100 = pas de bonus, pas de malus
    Bonus_Malus > 100 & Bonus_Malus <= 150 ~ "Malus modéré",
    Bonus_Malus > 150 & Bonus_Malus <= 250 ~ "Malus élevé",
    Bonus_Malus > 250 & Bonus_Malus <= 350 ~ "Malus très élevé",
    TRUE ~ "Erreur" 
  ))

data <- data %>%
  mutate(TrancheCar_Power = case_when(
    Car_Power <= 6 ~ "Puissance --",
    Car_Power > 6 & Car_Power <= 10 ~ "Puissance -",
    Car_Power > 10 & Car_Power <= 12 ~ "Puissance +",
    Car_Power > 12 ~ "Puissance ++",
    TRUE ~ "Erreur" 
  ))
```

# Modélisation

```{r}
train.index <- createDataPartition(data$Claim, p = .7, list = FALSE)
train <- data[ train.index,] 
test  <- data[-train.index,]

# Préparer les données d'entraînement
x_train <- train %>% 
  dplyr::select(-Claim) %>%
  dplyr::select_if(is.numeric) %>%
  as.matrix()
y_train <- train$Claim

# Préparer les données de test
x_test <- test %>% 
  dplyr::select(-Claim) %>%
  dplyr::select_if(is.numeric) %>%
  as.matrix()
y_test <- test$Claim
```

## Model A: Simple case
Avec simplement les données comme tel:
```{r}
model.complet <- lm(Claim~., data=train)
summary(model.complet)$coefficients %>%
  round(4) %>%
  kbl() %>%
  kable_styling(full_width = FALSE,)
```



```{r}
anova(model.complet)
```
```{r}
y_pred <- predict(model.complet, test %>%  dplyr::select(-Claim))
metrics_complet <- tibble(
  RMSE_C = rmse_c(y_test, y_pred),
  MSE = mean((y_test - y_pred)^2),
  RMSE = rmse(y_test, y_pred),
  R2 = R2(y_pred, y_test)
)

metrics_complet %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

## Model B: Lasso
```{r}
grid = 10^seq(0,-3,length=100)

model.lasso <- cv.glmnet(
  x_train, y_train, 
  alpha = 1, 
  lambda = grid, 
  preProc = c("center", "scale"),
  method = "glmnet",
  trControl = custom)
plot(model.lasso)
```


```{r}
# Prédictions sur x_test pour chaque lambda
preds <- predict(model.lasso, x_test, s = grid)

# Calcul du MSE, biais² et variance
mse <- colMeans((preds - y_test)^2)
biais2 <- (colMeans(preds) - mean(y_test))^2
variance <- apply(preds, 2, var)

# Construire le dataframe pour le plot
df_plot <- data.frame(
  lambda = grid,
  MSE = mse/max(mse),
  Biais2 = biais2/max(biais2),
  Variance = variance/max(variance)
) %>%
  mutate(lambda_log = log(lambda))

ggplot(df_plot, aes(x = lambda_log)) +
  geom_line(aes(y = MSE, color = "MSE"), linewidth = 0.7) +
  geom_line(aes(y = Biais2, color = "Biais²"), linewidth = 0.7) +
  geom_line(aes(y = Variance, color = "Variance"), linewidth = 0.7) +
  scale_color_manual(values = c("MSE" = "black", "Biais²" = "blue", "Variance" = "red")) +
  labs(x = "log(Lambda)", y = "Mean Squarred Error", title = "Biais, Variance et MSE en fonction de Lambda") +
  geom_vline(xintercept=log(model.lasso$lambda.min), color="gray")+
  theme_minimal()
```
Sur des données test, l’optimum peut être à $\lambda$ faible car le modèle a besoin d’une certaine complexité pour bien généraliser. A priori c'est un modèle dense.
```{r}
coef(model.lasso, s = model.lasso$lambda.min) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "Variable") %>%
  rename(Coefficient = `s1`) %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r}
# Calcul des métriques
y_pred <- predict(model.lasso, newx = x_test, s = model.lasso$lambda.min)
metrics_lasso <- tibble(
  RMSE_C = rmse_c(y_test,y_pred),
  MSE = mean((y_test - y_pred)^2),
  RMSE = rmse(y_test, y_pred),
  R2 = R2(y_pred, y_test)
)

metrics_lasso %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```


## Model C: Ridge
```{r}
grid = 10^seq(3,-3,length=100)

model.ridge <- cv.glmnet(
  x_train, y_train, 
  alpha = 0, 
  lambda = grid, 
  preProc = c("center", "scale"),
  method = "glmnet",
  trControl = cumstom)
plot(model.ridge)
```


```{r}
# Prédictions sur x_test pour chaque lambda
preds <- predict(model.ridge, x_test, s = grid)

# Calcul du MSE, biais² et variance
mse <- colMeans((preds - y_test)^2)
biais2 <- (colMeans(preds) - mean(y_test))^2
variance <- apply(preds, 2, var)

# Construire le dataframe pour le plot
df_plot <- data.frame(
  lambda = grid,
  MSE = mse/max(mse),
  Biais2 = biais2/max(biais2),
  Variance = variance/max(variance)
) %>%
  mutate(lambda_log = log(lambda))

ggplot(df_plot, aes(x = lambda_log)) +
  geom_line(aes(y = MSE, color = "MSE"), linewidth = 0.7) +
  geom_line(aes(y = Biais2, color = "Biais²"), linewidth = 0.7) +
  geom_line(aes(y = Variance, color = "Variance"), linewidth = 0.7) +
  scale_color_manual(values = c("MSE" = "black", "Biais²" = "blue", "Variance" = "red")) +
  labs(x = "log(Lambda)", y = "Mean Squarred Error", title = "Biais, Variance et MSE en fonction de Lambda") +
  geom_vline(xintercept=log(model.lasso$lambda.min), color="gray")+
  theme_minimal()
```

```{r}
# Calcul des métriques
y_pred <- predict(model.ridge, newx = x_test, s = model.ridge$lambda.min)
metrics_ridge <- tibble(
  RMSE_C = rmse_c(y_test,y_pred),
  MSE = mean((y_test - y_pred)^2),
  RMSE = rmse(y_test, y_pred),
  R2 = R2(y_pred, y_test)
)

metrics_lasso %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```
```{r}
names(train)
```


## Model D:

```{r}
C_1 <- which(train$Claim %in% c(0, 1))
C_2 <- which(train$Claim == 2)
C_3 <- which(train$Claim == 3)
C_4 <- which(train$Claim > 2)

n1 <- length(which(train$Claim %in% c(0, 1)))
n2 <- length(which(train$Claim == 2))
n3 <- length(which(train$Claim == 3))
n4 <- length(which(train$Claim > 3))

# Référence
n_max <- max(n1, n2, n3, n4)

# Calculer les poids pour équilibrer l'importance des classes
w <- numeric(length(train$Claim))  
w[C_1] <- n_max / n1  # Plus n1 est petit, plus le poids est grand
w[C_2] <- n_max / n2
w[C_3] <- n_max / n3
w[C_4] <- n_max / n4  # Classe rare => poids plus grand
```

```{r}
model.big <- lm(
  Claim ~ . 
    + I(Bonus_Malus/Period_Exp) + I(Bonus_Malus*Period_Exp) 
    + I(Age*Bonus_Malus) + I(Age/Bonus_Malus)  
    + I(Age*Period_Exp) + I(Age/Period_Exp)
    + I(Period_Exp*Bonus_Malus*Age) + I(Period_Exp*Bonus_Malus/Age), 
  preProc = c("center", "scale"),
  weights=w,
  data=train)

summary(model.big)$coefficients %>%
  round(4) %>%
  kbl() %>%
  kable_styling(full_width = FALSE)
```

```{r}
y_pred <- predict(model.big, test)
metrics_big <- tibble(
  RMSE_C = rmse_c(y_test, y_pred),
  MSE = mean((y_test - y_pred)^2),
  RMSE = rmse(y_test, y_pred),
  MAE = mae(y_test, y_pred),
  R2 = R2(y_pred, y_test)
)

metrics_big %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r}
n <- dim(data)[1]
model.step <- stepAIC(model.big, Claim ~ ., trace=FALSE, k=log(n), direction="backward")
model.step
```


```{r}
summary(model.step)$coefficients %>%
  round(4) %>%
  kbl() %>%
  kable_styling(full_width = FALSE)
```

```{r}
y_pred <- predict(model.step, test %>%  dplyr::select(-Claim))
metrics_complet <- tibble(
  RMSE_C = rmse_c(y_test, y_pred),
  MSE = mean((y_test - y_pred)^2),
  RMSE = rmse(y_test, y_pred),
  R2 = R2(y_pred, y_test)
)

metrics_complet %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```


